#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
  rrd-navtiming
  ~~~~~~~~~~~~~

  This script provides simple, minimal and robust storage for a small
  set of time-series metrics. The idea is not to replace a full-fledged
  time-series database but to implement the bare minimum subset of
  features required to power a site like <https://status.github.com/>.

  rrd-navtiming subscribes to NavigationTiming events via EventLogging
  and it updates a pair of RRD files in its working directory: mobile.rrd
  and desktop.rrd. If the files do not exist, they are created.


  Usage:

    rrd-navtiming [--endpoint ENDPOINT] [--log-path LOG_PATH] RRD_FILE

      --endpoint ENDPOINT   EventLogging endpoint URI
                            (default: tcp://eventlogging.eqiad.wmnet:8600)

      --log-path LOG_PATH   Path to use for log files
                            (default: log to stderr only)

  Example:

    rrd-navtiming --endpoint tcp://eventlog1001.eqiad.wmnet:8600 \
                  /var/lib/rrd-navtiming/rrd-navtiming.rrd


  Requirements:

  * eventlogging
      https://github.com/wikimedia/mediawiki-extensions-EventLogging/
      (the Python module is in server/).

  * rrdtool
      http://oss.oetiker.ch/rrdtool/prog/rrdpython.en.html


  Futher reading:

  * https://meta.wikimedia.org/wiki/Schema:NavigationTiming
  * https://www.mediawiki.org/wiki/Extension:NavigationTiming


  Copyright 2015 Ori Livneh <ori@wikimedia.org>

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.

"""
from __future__ import division

import sys
reload(sys)
sys.setdefaultencoding('utf-8')

import argparse
import bisect
import heapq
import logging
import os
import threading
import time

import eventlogging
import rrdtool


METRICS = (
    'responseStart',  # Time to user agent receiving first byte
    'firstPaint',     # Time to initial render
    'domComplete',    # Time to DOM Comlete event
    'loadEventEnd',   # Time to load event completion
)

# Size of sliding window, in seconds.
WINDOW_SPAN = 300

# Only push an update if we have at least this many samples.
SAMPLE_THRESHOLD = 200

# Aggregation intervals.
INTERVALS = (
    60 * 60,                # Hour
    60 * 60 * 24,           # Day
    60 * 60 * 24 * 7,       # Week
    60 * 60 * 24 * 30,      # Month
    60 * 60 * 24 * 365.25,  # Year
)

# Store 120 values at each resolution. This makes graphing simpler,
# because we're always working with a fixed number of points.
ROWS = 120

# We will push an aggregate value as often as we need in order to have
# ROWS many values at the smallest INTERVAL.
STEP = INTERVALS[0] / ROWS

# STEP should be a whole number that divides each INTERVAL.
assert STEP.is_integer()
for interval in INTERVALS:
    assert (interval / ROWS / STEP).is_integer()

# Set the maximum acceptable interval between samples ("heartbeat") to a
# full day. This means RRD will record an estimate for missing samples as
# long as it has at least one sample from the last 24h to go by. If we go
# longer than 24h without reporting a measurement, RRD will record a value
# of UNKNOWN instead.
HEARTBEAT = 60 * 60 * 24

# The expected range for measurements is 0 - 60,000 milliseconds.
MIN, MAX = 0, 60 * 1000

# List of data source ('DS') definitions in the format expected by
# rrdcreate (<http://oss.oetiker.ch/rrdtool/doc/rrdcreate.en.html>).
SOURCES = ['DS:%s:GAUGE:%d:%d:%d' % (metric, HEARTBEAT, MIN, MAX)
           for metric in METRICS]

# List of round-robin archive ('RRA') definitions in rrdcreate format.
ARCHIVES = ['RRA:AVERAGE:0.5:%d:%d' % (interval / ROWS / STEP, ROWS)
            for interval in INTERVALS]


class SlidingWindow(object):
    """Represents a sliding window of measurements."""

    def __init__(self, span, initial=()):
        """Initialize. `span` is the size of the window, in seconds."""
        self.heap = []
        self.span = span
        self.lock = threading.Lock()

    def add(self, timestamp, data):
        """Add an item to the window."""
        cutoff = time.time() - self.span
        with self.lock:
            heapq.heappush(self.heap, (timestamp, data))
            while self.heap and self.heap[0][0] < cutoff:
                heapq.heappop(self.heap)

    def items(self):
        """Returns a copy of the list of items in the window."""
        cutoff = time.time() - self.span
        items = list(self.heap)
        while items and items[0][0] < cutoff:
            heapq.heappop(items)
        return items


def setup_logging(log_path=None):
    """Get the `rrd-navtiming` logger and add handlers for stdout
    and (optionally) a file."""
    log = logging.getLogger('rrd-navtiming')
    if log.handlers:
        return log
    handlers = [logging.StreamHandler(stream=sys.stderr)]
    if log_path:
        # Create a log file. It will be rotated whenever its size
        # exceeds 50MB, and 10 archives will be retained.
        handlers.append(logging.handlers.RotatingFileHandler(
            os.path.join(log_path, 'rrd-navtiming.log'), backupCount=10,
            maxBytes=(50 * 1000 * 1000)))
    formatter = logging.Formatter('[%(asctime)s] %(message)s')
    log.setLevel(logging.INFO)
    for log_handler in handlers:
        log_handler.setFormatter(formatter)
        log_handler.setLevel(logging.INFO)
        log.addHandler(log_handler)
    return log


def update_rrd(rrd_file, window):
    """Push updates to RRD."""
    samples = accumulate(window.items(), SAMPLE_THRESHOLD)
    try:
        update = 'N:' + ':'.join(str(samples[metric]) for metric in METRICS)
    except KeyError as e:
        log.warning('No value for metric "%s"; update skipped.', e.args[0])
    else:
        rrdtool.update(rrd_file, update)
        log.info(update)


def median(population):
    """Compute the median of a sorted list."""
    length = len(population)
    if not length:
        raise ValueError('Cannot compute median of empty list.')
    index = (length - 1) // 2
    if length % 2:
        return population[index]
    return sum(population[index:index + 2]) / 2


def accumulate(window, threshold=0):
    """Group samples by metric and compute medians."""
    data = {metric: [] for metric in METRICS}
    for _, event in window:
        for metric in METRICS:
            value = event.get(metric)
            if value:
                bisect.insort(data[metric], value)
    return {m: median(vs) for m, vs in data.items() if len(vs) > threshold}


def create_rrd(rrd_file, step, sources, archives, start='N'):
    args = [rrd_file, '--no-overwrite', '--step', step, '--start', start]
    args.extend(sources)
    args.extend(archives)
    try:
        rrdtool.create(*map(str, args))
        log.info('Created %s', rrd_file)
    except Exception as e:
        if 'File exists' not in e.message:
            raise
        log.info('RRD file %s already exists.', rrd_file)


if __name__ == '__main__':
    ap = argparse.ArgumentParser(description='Navigation Timing RRD logger')
    ap.add_argument('rrd', help='RRD file path', type=os.path.abspath)
    ap.add_argument('--endpoint', help='Endpoint URI (default: '
                    'tcp://eventlogging.eqiad.wmnet:8600)',
                    default='tcp://eventlogging.eqiad.wmnet:8600')
    ap.add_argument('--log-path', help='Path to use for log files (default: '
                    'log to stderr only).', type=os.path.abspath)
    args = ap.parse_args()

    log = setup_logging(args.log_path)
    log.info('Starting up...')

    window = SlidingWindow(WINDOW_SPAN)
    create_rrd(args.rrd, step=STEP, sources=SOURCES, archives=ARCHIVES)

    worker = eventlogging.PeriodicThread(interval=STEP, target=update_rrd,
                                         args=(args.rrd, window))
    worker.daemon = True
    time_start = time.time()

    log.info('Connecting to <%s>...', args.endpoint)
    events = eventlogging.connect(args.endpoint)

    for meta in events.filter(schema='NavigationTiming'):
        window.add(meta['timestamp'], meta['event'])
        if not worker.isAlive() and time.time() - time_start >= WINDOW_SPAN:
            worker.start()
